# Sentiment Analysis

<p>
<img alt="Google Cloud" src="https://img.shields.io/badge/googlecloud-%234285F4.svg?&style=for-the-badge&logo=googlecloud&logoColor=white"/>
<img alt="Terraform" src="https://img.shields.io/badge/terraform-%237b42bc.svg?&style=for-the-badge&logo=terraform&logoColor=white"/>
<img alt="Kubernetes" src="https://img.shields.io/badge/kubernetes-%23326ce5.svg?&style=for-the-badge&logo=kubernetes&logoColor=white"/>
<img alt="Docker" src="https://img.shields.io/badge/docker-%232496ED.svg?&style=for-the-badge&logo=docker&logoColor=white"/>
</p>


## How to start

Download the dataset files stored at `gs://sentiment-analysis-240222` with the following make target:

```shell
make pull
```

Install [poetry](https://python-poetry.org/) to manage the dependencies and virtual environment, so install the packages by the following:

```shell
poetry install
```

Then, enter into the virtual environment shell:

```shell
poetry shell
```

# Compute engine deployment

The following steps presents how to deploy a virtual machine as a development environment for this application. First, you must install Terraform and provide you Google Cloud credentials. Then, change the project name and region in the `gcp/compute/variables.tf`:

```terraform
variable "project" {
  default = "weather-297102"
}

variable "region" {
  default = "us-central1"
}

variable "zone" {
  default = "us-central1-c"
}
```

So, create a bucket to be used to store the states generated by Terraform:

```shell
make tf-backend
```

Finally, init, plan and apply the Terraform resources as the following:

```shell
cd ./gcp/compute
terraform init
terraform plan
terraform apply
```

The external IP of the virtual machine created can be found by listing the compute instances of your project, as the following command:

```shell
gcloud compute instances list
```

To continue with the deployment, you must enter into the shell command line of the virtual machine:

```shell
gcloud compute ssh sentiment-analysis-instance
```

With the virtual machine up, you can clone this repository and run the `scripts/install-dependencies.sh` script. It will install jupyter lab and their dependencies. Also, a service is created to auto start the jupyter lab server at port 80:

```shell
git clone https://github.com/himewel/sentiment-analysis
cd sentiment-analysis
sudo bash ./scripts/install-dependencies.sh
```

Then, you can repeat the step at the *How to start* section and then start the application server:

```shell
sudo python3 src/application.py
```

# Kubernetes engine deployment

Similar to the first steps at Compute Engine Deployment, you have to declare project, region and credentials to apply the Terraform modules. So, you will be able to apply the `gcp/kubernetes` modules and create a GKE cluster, a VPC network where the nodes will get an address, and a Container Registry to store the Docker image of the project, as the following:

```shell
cd ./gcp/kubernetes
terraform init
terraform plan
terraform apply
```

In a few minutes you can check if your cluster was created with:

```shell
gcloud container clusters list
```

Then, build and push a Docker image of the project to a repository visible to GKE. You can do this as the following:

```shell
# get the credentials to push the image
gcloud auth configure-docker
# so build and push the image
docker build . --tag gcr.io/weather-297102/sentiment-analysis
docker push gcr.io/weather-297102/sentiment-analysis
```

Now you can create the pods where your application will be deployed in the Kubernetes cluster with [kubectl](https://kubernetes.io/docs/tasks/tools/):

```shell
# get the credentials to manage you cluster
gcloud container clusters get-credentials sentiment-analysis-gke
# create the services declared in ./templates
kubectl apply -f templates
```

Finally, check the services to get the endpoint where the API will be provided:

```shell
kubectl get services
```
